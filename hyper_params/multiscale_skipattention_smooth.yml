project: Thesis
name: Skip Attention

parameters:
    model name: 'MultiScaleSkipAttentionWithSmoothness'
    model class: 'SkipAttentionModel'
    encoder type: 'gated'

    multiscale: True
    smoothness loss: True
    lambda l1: 0.9
    lambda smooth: 0.01
    
    batch size: 8
    lr: 0.0001
    monitor: 'val_loss_total'
    epochs: 12
